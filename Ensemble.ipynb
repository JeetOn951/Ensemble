{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Theoretical Questions :**"
      ],
      "metadata": {
        "id": "0EP3K0a6v5Qc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. What is Ensemble Learning in Machine Learning? Explain the key idea behind it.**\n",
        "\n",
        "- Ensemble Learning is a machine learning technique that combines multiple individual models, often called **base learners** or **weak learners**, to create a more powerful and accurate predictive model.  \n",
        "The main idea is that a group of weak models, when combined properly, can outperform any single strong model.\n",
        "\n",
        "In ensemble learning, each model contributes to the final prediction, and the errors made by one model are compensated by others.  \n",
        "This leads to better generalization, higher accuracy, and reduced overfitting.\n",
        "\n",
        "There are two main types of ensemble methods:\n",
        "\n",
        "1. **Bagging (Bootstrap Aggregating):**\n",
        "   - Multiple models are trained independently on random subsets of the data (with replacement).\n",
        "   - Final prediction is made by averaging (for regression) or voting (for classification).\n",
        "   - Example: **Random Forest**\n",
        "\n",
        "2. **Boosting:**\n",
        "   - Models are trained sequentially, where each new model focuses more on correcting the errors of the previous ones.\n",
        "   - Example: **AdaBoost, Gradient Boosting, XGBoost**\n",
        "\n",
        "3. **Stacking:**\n",
        "   - Multiple models (base learners) make predictions, and a meta-model learns to combine these predictions optimally.\n",
        "\n",
        "**Key Idea:**  \n",
        "> “The wisdom of the crowd” — combining multiple diverse models leads to a more accurate and robust overall prediction than relying on a single model.\n"
      ],
      "metadata": {
        "id": "GEB_Wx1av_Jz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. What is the difference between Bagging and Boosting?**\n",
        "\n",
        "- **Bagging (Bootstrap Aggregating)** and **Boosting** are both ensemble learning techniques used to improve model accuracy by combining multiple models,  \n",
        "but they differ in how these models are trained and combined.\n",
        "\n",
        "| Feature | Bagging | Boosting |\n",
        "|----------|----------|-----------|\n",
        "| **Objective** | Reduce variance and prevent overfitting | Reduce bias and improve weak learners |\n",
        "| **Training Method** | Models are trained **independently** on random subsets of data (with replacement) | Models are trained **sequentially**, each new model focuses on the errors of the previous one |\n",
        "| **Data Sampling** | Uses **bootstrap sampling** (random sampling with replacement) | Uses the **entire dataset**, but assigns higher weights to misclassified samples |\n",
        "| **Model Weighting** | All models have **equal weight** in the final prediction | Models are **weighted based on their performance** |\n",
        "| **Error Handling** | Each model works independently, so errors are averaged out | Each subsequent model tries to **correct** the previous model’s errors |\n",
        "| **Overfitting Tendency** | Less prone to overfitting | More prone to overfitting if not regularized properly |\n",
        "| **Examples** | Random Forest | AdaBoost, Gradient Boosting, XGBoost |\n",
        "\n",
        "**In summary:**  \n",
        "- **Bagging** reduces **variance** by averaging predictions from independent models.  \n",
        "- **Boosting** reduces **bias** by sequentially improving weak models to create a strong learner.\n"
      ],
      "metadata": {
        "id": "IoRckPNdwOY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. What is bootstrap sampling and what role does it play in Bagging methods like Random Forest?**\n",
        "\n",
        "- **Bootstrap sampling** is a statistical technique in which multiple random samples are drawn **with replacement** from the original dataset.  \n",
        "Each sample (called a **bootstrap sample**) has the same size as the original dataset, but because of replacement, some data points may appear multiple times, while others may not appear at all.\n",
        "\n",
        "**Role in Bagging (e.g., Random Forest):**\n",
        "\n",
        "1. **Diversity Creation:**  \n",
        "   - Each model (like a decision tree in Random Forest) is trained on a different bootstrap sample.\n",
        "   - This introduces variability among the models, making them less correlated.\n",
        "\n",
        "2. **Variance Reduction:**  \n",
        "   - Since each model is trained on a slightly different dataset, their errors tend to cancel each other out when combined.\n",
        "   - The final prediction (by averaging or voting) becomes more stable and less sensitive to noise.\n",
        "\n",
        "3. **Improved Generalization:**  \n",
        "   - By combining diverse models trained on different samples, the ensemble generalizes better to unseen data.\n",
        "\n",
        "**In summary:**  \n",
        "> Bootstrap sampling allows Bagging methods like Random Forest to create multiple diverse training datasets from the same data,  \n",
        "> leading to a robust ensemble that reduces variance and improves predictive performance.\n"
      ],
      "metadata": {
        "id": "KU89M0jhwdQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. What are Out-of-Bag (OOB) samples and how is OOB score used to evaluate ensemble models?**\n",
        "\n",
        "- In **Bagging methods** such as **Random Forest**, each base model (e.g., decision tree) is trained on a **bootstrap sample** of the dataset —  \n",
        "that is, a random sample **with replacement**. As a result, some data points are not included in this sample.\n",
        "\n",
        "These data points that are **not selected** in the bootstrap sample for a particular model are called **Out-of-Bag (OOB) samples**.\n",
        "\n",
        "### **Role of OOB Samples:**\n",
        "- OOB samples act as a **built-in validation set** for each model.\n",
        "- Since a model hasn’t seen its OOB samples during training, they can be used to test that model’s performance.\n",
        "\n",
        "### **OOB Score:**\n",
        "- The **OOB score** is the average accuracy (or error) computed by predicting the OOB samples across all models in the ensemble.\n",
        "- It provides an **unbiased estimate of the model’s performance** without needing a separate validation or test set.\n",
        "\n",
        "### **Advantages of Using OOB Score:**\n",
        "1. Eliminates the need for a separate validation dataset.\n",
        "2. Provides an efficient and quick way to estimate model accuracy.\n",
        "3. Helps detect overfitting in ensemble models.\n",
        "\n",
        "**In summary:**  \n",
        "> **OOB samples** are the unused data points in bootstrap sampling, and the **OOB score** evaluates model accuracy using those samples,  \n",
        "> serving as an internal cross-validation method in ensemble techniques like Random Forest.\n"
      ],
      "metadata": {
        "id": "42tYsC3mwsAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.  Compare feature importance analysis in a single Decision Tree vs. a Random Forest.**\n",
        "\n",
        "- **Feature importance** measures how much each feature contributes to predicting the target variable.  \n",
        "Both **Decision Tree** and **Random Forest** provide feature importance scores, but they differ in how these scores are calculated and interpreted.\n",
        "\n",
        "| Aspect | Decision Tree | Random Forest |\n",
        "|---------|----------------|----------------|\n",
        "| **Model Type** | Single model | Ensemble of many decision trees |\n",
        "| **Computation Method** | Calculated based on the **reduction in impurity** (e.g., Gini or entropy) caused by each feature during splits | Computed as the **average of feature importance scores** across all trees in the forest |\n",
        "| **Stability** | Can be **unstable** — small changes in data can lead to large differences in feature importance | More **stable and reliable**, as it aggregates results from many trees |\n",
        "| **Bias** | May be **biased** toward features with more categories or continuous values | Bias is **reduced** due to averaging over multiple trees |\n",
        "| **Interpretation** | Shows how important a feature is **for one specific tree** | Shows the **overall importance** of each feature across the entire ensemble |\n",
        "| **Overfitting Tendency** | High — single tree may overfit, giving misleading importance | Lower — averaging across trees gives more **generalized importance** |\n",
        "\n",
        "**In summary:**  \n",
        "> A **Decision Tree** provides feature importance for a single model and may be unstable,  \n",
        "> whereas a **Random Forest** gives a more **robust and generalizable** estimate of feature importance by averaging across many trees.\n"
      ],
      "metadata": {
        "id": "2dlbAMC5w7px"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Practical Questions :**"
      ],
      "metadata": {
        "id": "xRSYxYKFfLMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Write a Python program to:\n",
        "# ● Load the Breast Cancer dataset using sklearn.datasets.load_breast_cancer()\n",
        "# ● Train a Random Forest Classifier\n",
        "# ● Print the top 5 most important features based on feature importance scores.\n",
        "# (Include your Python code and output in the code box below.)\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get feature importances\n",
        "importances = pd.Series(model.feature_importances_, index=data.feature_names)\n",
        "\n",
        "# Sort and get top 5 features\n",
        "top_features = importances.sort_values(ascending=False).head(5)\n",
        "\n",
        "# Print top 5 most important features\n",
        "print(\"Top 5 Most Important Features:\")\n",
        "print(top_features)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlbXJ5zYxOjA",
        "outputId": "d4a13321-832b-4aa1-b8bb-f9014f9085a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Most Important Features:\n",
            "worst area              0.139357\n",
            "worst concave points    0.132225\n",
            "mean concave points     0.107046\n",
            "worst radius            0.082848\n",
            "worst perimeter         0.080850\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) Write a Python program to:\n",
        "# ● Train a Bagging Classifier using Decision Trees on the Iris dataset\n",
        "# ● Evaluate its accuracy and compare with a single Decision Tree\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# (Optional) Add slight noise to make the problem less trivial\n",
        "X = X + np.random.normal(0, 0.2, X.shape)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train a single Decision Tree\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_predictions = dt_model.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
        "\n",
        "# Train a Bagging Classifier using Decision Trees (with limited depth)\n",
        "bagging_model = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=3),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bagging_model.fit(X_train, y_train)\n",
        "bagging_predictions = bagging_model.predict(X_test)\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_predictions)\n",
        "\n",
        "# Print the accuracies\n",
        "print(\"Accuracy of Single Decision Tree: {:.2f}%\".format(dt_accuracy * 100))\n",
        "print(\"Accuracy of Bagging Classifier: {:.2f}%\".format(bagging_accuracy * 100))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGTbULu6xxp9",
        "outputId": "745f1bc3-ee2e-45ab-b8db-c5152aa17f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Single Decision Tree: 95.56%\n",
            "Accuracy of Bagging Classifier: 95.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) Write a Python program to:\n",
        "# ● Train a Random Forest Classifier\n",
        "# ● Tune hyperparameters max_depth and n_estimators using GridSearchCV\n",
        "# ● Print the best parameters and final accuracy\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Add slight random noise to make classification less trivial\n",
        "X = X + np.random.normal(0, 0.2, X.shape)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Define the model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define the parameter grid for tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100],\n",
        "    'max_depth': [2, 4, 6, 8, None]\n",
        "}\n",
        "\n",
        "# Perform Grid Search with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Parameters Found:\", grid_search.best_params_)\n",
        "print(\"Final Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05Aw_yL7yeGy",
        "outputId": "308b7925-6668-4b07-9687-b9a0c29deccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters Found: {'max_depth': 4, 'n_estimators': 50}\n",
            "Final Accuracy: 95.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9) Write a Python program to:\n",
        "# ● Train a Bagging Regressor and a Random Forest Regressor on the California Housing dataset\n",
        "# ● Compare their Mean Squared Errors (MSE)\n",
        "\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train a Bagging Regressor with shallow trees\n",
        "bagging_reg = BaggingRegressor(\n",
        "    estimator=DecisionTreeRegressor(max_depth=6),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bagging_reg.fit(X_train, y_train)\n",
        "bagging_pred = bagging_reg.predict(X_test)\n",
        "bagging_mse = mean_squared_error(y_test, bagging_pred)\n",
        "\n",
        "# Train a Random Forest Regressor with the same depth\n",
        "rf_reg = RandomForestRegressor(\n",
        "    n_estimators=50,\n",
        "    max_depth=6,\n",
        "    random_state=42\n",
        ")\n",
        "rf_reg.fit(X_train, y_train)\n",
        "rf_pred = rf_reg.predict(X_test)\n",
        "rf_mse = mean_squared_error(y_test, rf_pred)\n",
        "\n",
        "# Print and compare the Mean Squared Errors\n",
        "print(\"Mean Squared Error (Bagging Regressor): {:.4f}\".format(bagging_mse))\n",
        "print(\"Mean Squared Error (Random Forest Regressor): {:.4f}\".format(rf_mse))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dARErNNoyiKU",
        "outputId": "357911c5-b256-4d6b-9c07-c4ab27bb1821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (Bagging Regressor): 0.4126\n",
            "Mean Squared Error (Random Forest Regressor): 0.4126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. You are working as a data scientist at a financial institution to predict loan default. You have access to customer demographic and transaction history data. You decide to use ensemble techniques to increase model performance. Explain your step-by-step approach to:**\n",
        "         ● Choose between Bagging or Boosting\n",
        "         ● Handle overfitting\n",
        "         ● Select base models\n",
        "         ● Evaluate performance using cross-validation\n",
        "         ● Justify how ensemble learning improves decision-making in this real-world context.  \n",
        "\n",
        "\n",
        "- Ensemble approach for predicting loan default — step-by-step\n",
        "\n",
        "Context:\n",
        "We have customer demographic + transaction-history data and must predict loan default (binary classification). Business constraints: class imbalance, regulatory need for explainability, cost of false negatives (missed defaults) vs false positives (unnecessary denial).\n",
        "\n",
        "1) Choosing between Bagging and Boosting\n",
        "\n",
        "Decision rule:\n",
        "- Use **Bagging (e.g., Random Forest)** when:\n",
        "  - The main problem is **high variance** (models overfit to training data).\n",
        "  - Data may contain noisy labels, and we want robust estimates.\n",
        "  - We want simpler hyperparameter tuning and faster parallel training.\n",
        "- Use **Boosting (e.g., Gradient Boosting, XGBoost, LightGBM, CatBoost)** when:\n",
        "  - The main problem is **high bias** (weak learners underfit).\n",
        "  - We want to squeeze maximum predictive accuracy from features.\n",
        "  - We can control overfitting (early stopping, regularization) and accept sequential training.\n",
        "Practical choice for loan default:\n",
        "- Start with **Random Forest** as a baseline (robust, interpretable feature importances).\n",
        "- Use **Boosted Trees** (LightGBM/XGBoost/CatBoost) next to improve performance and capture subtle patterns.\n",
        "- Final choice: ensemble (stack) of both families if regulatory & compute budgets allow.\n",
        "\n",
        "2) Handling overfitting\n",
        "\n",
        "Techniques to apply (training & model-level):\n",
        "- **Data level**\n",
        "  - More data if possible (historical transactions).\n",
        "  - Feature engineering & careful cross-validation — avoid leakage (time-based CV for temporal features).\n",
        "- **Model regularization**\n",
        "  - For Decision Trees / RF: limit `max_depth`, `min_samples_leaf`, `min_samples_split`.\n",
        "  - For Boosting: use `learning_rate` (small), `n_estimators` with early stopping on validation, `max_depth`, `subsample`, `colsample_bytree`.\n",
        "- **Sampling**\n",
        "  - Use bootstrap + subsample features (RF) or row/feature subsampling (boosting) to reduce correlation.\n",
        "- **Early stopping**\n",
        "  - Monitor validation metric (AUC/PR-AUC/cost metric) and stop when no improvement.\n",
        "- **Feature selection / dimensionality reduction**\n",
        "  - Remove leakage features, use domain-driven features, or apply regularized models to select features.\n",
        "- **Ensemble averaging / stacking**\n",
        "  - Blend multiple model families to reduce variance.\n",
        "- **Model stability checks**\n",
        "  - Retrain with different seeds and confirm consistent performance.\n",
        "- **Calibration**\n",
        "  - After training, calibrate probabilities (Platt scaling, isotonic) to avoid overconfident predictions.\n",
        "\n",
        "3) Selecting base models\n",
        "\n",
        "Practical candidates:\n",
        "- **Decision Tree** (as base learner for bagging; shallow trees for robustness)\n",
        "- **Random Forest** (bagging ensemble) — good baseline\n",
        "- **Gradient Boosted Trees** (XGBoost / LightGBM / CatBoost) — high accuracy for tabular data\n",
        "- **Logistic Regression with regularization** — strong, interpretable baseline; good for scorecards\n",
        "- **Simple neural networks** or **MLP** only if many high-dim engineered features exist\n",
        "How to choose:\n",
        "- Start simple (Logistic) → baseline.\n",
        "- Add Random Forest for variance reduction.\n",
        "- Add a tuned GBT for top accuracy.\n",
        "- Optionally use stacking: meta-learner (regularized LR) that combines RF + GBT + LR predictions.\n",
        "\n",
        "4) Evaluate performance using cross-validation\n",
        "\n",
        "Design CV carefully to reflect production use:\n",
        "- **Stratified K-fold** for balanced class representation (e.g., stratified 5 or 10 folds).\n",
        "- If data is time-ordered (transactions), use **time-based CV** (walk-forward / rolling window) to prevent leakage.\n",
        "- Use **nested CV** for robust hyperparameter tuning:\n",
        "  - Outer loop: estimate generalization (k folds).\n",
        "  - Inner loop: hyperparameter tuning (grid/random/optuna).\n",
        "- **Metrics**:\n",
        "  - Primary: **AUC-ROC** and **Precision-Recall AUC** (PR-AUC is critical if positives are rare).\n",
        "  - Business metrics: **Expected Loss**, **Cost-weighted error**, or **Profit/Loss** based on credit decision cost matrix.\n",
        "  - Secondary: Accuracy, F1-score, but avoid relying solely on accuracy for imbalanced data.\n",
        "- **Probability calibration & evaluation**:\n",
        "  - Use **Brier score**, **calibration plots**, and **reliability diagrams** to check predicted probabilities.\n",
        "- **Stability & fairness checks**:\n",
        "  - Evaluate across cohorts (age groups, geography, income bands) for performance drift or bias.\n",
        "- **Confidence intervals & statistical tests**:\n",
        "  - Use bootstrapping or repeated CV to get confidence intervals for metrics; compare models statistically before deployment.\n",
        "\n",
        "5) Practical pipeline (high-level)\n",
        "\n",
        "- Data ingestion & cleaning (handle missing values, outliers, feature engineering).\n",
        "- Create transaction-level aggregates (recency, frequency, monetary, behavioral trends).\n",
        "- Split: time-ordered holdout or stratified CV.\n",
        "- Baseline: train Logistic Regression (regularized) → evaluate.\n",
        "- Train Random Forest (baseline ensemble) → tune `n_estimators`, `max_depth`, `min_samples_leaf`.\n",
        "- Train Gradient Boosted model → tune `n_estimators`, `learning_rate`, `max_depth`, `subsample`, `colsample_bytree`.\n",
        "- If helpful, train Bagging Regressor or BaggingClassifier variants.\n",
        "- Evaluate (nested CV), calibrate probabilities, and compute business KPIs (expected loss).\n",
        "- Perform explainability: SHAP / LIME / tree feature importances and produce per-decision explanations for regulatory records.\n",
        "- Model validation: backtesting on recent unseen months.\n",
        "- Deployment: monitor performance & drift; schedule model retraining.\n",
        "\n",
        "6) Justify how ensemble learning improves decision-making (business-ready)\n",
        "\n",
        "- **Higher predictive performance**: Ensembles (bagging and boosting) reduce variance/bias and typically produce more accurate risk scores than single models — leading to fewer missed defaults and fewer unnecessary denials.\n",
        "- **Robustness**: Bagging reduces sensitivity to noisy training examples; boosting captures subtle patterns. Combined, they yield stable predictions across customers.\n",
        "- **Better probability estimates (after calibration)**: Ensembles often produce more reliable ranking of risk; calibrated probabilities support better thresholding for lending decisions and consistent provisioning.\n",
        "- **Risk-adjusted decisions**: Improved discrimination allows fine-grained decision rules (e.g., accept/accept-with-conditions/reject), optimizing expected portfolio return and loss.\n",
        "- **Model explainability (operationalized)**: Tree-based ensembles allow feature importance and SHAP explanations which can be recorded for regulatory audits and for explaining adverse actions to customers.\n",
        "- **Operational benefits**: Reduced false negatives (missed defaulters) lowers expected credit losses. Reduced false positives improves customer experience and increases revenue.\n",
        "\n",
        "7) Additional operational & regulatory considerations\n",
        "\n",
        "- **Audit trail**: log features and model version for every decision.\n",
        "- **Bias & fairness checks**: test for disparate impact; implement mitigation strategies if required.\n",
        "- **Model governance**: document the model lifecycle, approvals, and performance monitoring plan.\n",
        "- **Monitoring**: track input feature distributions, performance metrics, calibration, and business KPIs. Trigger alerts and retraining if drift detected.\n",
        "- **Explainability for decisions**: produce short textual reasons from SHAP/top features for each declined applicant.\n",
        "\n",
        "8) Summary checklist (short)\n",
        "\n",
        "- [ ] Baseline: regularized Logistic Regression.\n",
        "- [ ] Bagging: Random Forest (baseline ensemble).\n",
        "- [ ] Boosting: LightGBM/XGBoost/CatBoost (tuned).\n",
        "- [ ] CV: nested, stratified or time-based as appropriate.\n",
        "- [ ] Metrics: AUC-ROC, PR-AUC, calibration, busi\n"
      ],
      "metadata": {
        "id": "SmVxEdSIzfOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensemble approach for loan-default prediction (ready for Colab)\n",
        "# - simulates demographic + transaction features\n",
        "# - trains RandomForest (bagging-style) and HistGradientBoosting (boosting-style)\n",
        "# - uses stratified CV, GridSearchCV, class imbalance handling, calibration check\n",
        "# - prints best params and final evaluation metrics\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score, accuracy_score, confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "from sklearn.inspection import permutation_importance\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# ===========================\n",
        "# 1) Simulate dataset\n",
        "# ===========================\n",
        "# We'll create a dataset that imitates: demographic (age, income) + transaction-derived features\n",
        "# Imbalanced target (default rare) to mimic real loan-default distribution.\n",
        "X, y = make_classification(\n",
        "    n_samples=20000,\n",
        "    n_features=20,\n",
        "    n_informative=8,\n",
        "    n_redundant=4,\n",
        "    n_repeated=0,\n",
        "    n_classes=2,\n",
        "    weights=[0.93, 0.07],   # ~7% defaults (class imbalance)\n",
        "    class_sep=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Create human-readable feature names: demographics and transaction aggregates\n",
        "feature_names = [\n",
        "    \"age\", \"annual_income\", \"loan_amount\", \"loan_term\", \"num_prev_loans\",\n",
        "    \"delinquency_count\", \"avg_monthly_balance\", \"std_monthly_balance\",\n",
        "    \"txn_freq_6mo\", \"txn_amt_mean\", \"txn_amt_std\", \"credit_utilization\",\n",
        "    \"num_credit_inquiries\", \"employment_years\", \"home_ownership_flag\",\n",
        "    \"months_since_last_default\", \"ratio_debit_credit\", \"savings_to_income\",\n",
        "    \"recent_large_txn_count\", \"avg_days_between_txn\"\n",
        "]\n",
        "X = pd.DataFrame(X, columns=feature_names)\n",
        "y = pd.Series(y, name=\"default\")\n",
        "\n",
        "print(\"Dataset shape:\", X.shape)\n",
        "print(\"Default rate: {:.2f}%\".format(y.mean() * 100))\n",
        "\n",
        "# ===========================\n",
        "# 2) Train / Test split (stratified)\n",
        "# ===========================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, stratify=y, random_state=42\n",
        ")\n",
        "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
        "\n",
        "# ===========================\n",
        "# 3) Baseline: Logistic Regression (simple, interpretable) - optional quick baseline\n",
        "# ===========================\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "baseline_pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42))\n",
        "])\n",
        "baseline_pipe.fit(X_train, y_train)\n",
        "y_pred_baseline = baseline_pipe.predict(X_test)\n",
        "y_prob_baseline = baseline_pipe.predict_proba(X_test)[:,1]\n",
        "print(\"\\nBaseline Logistic Regression (quick check):\")\n",
        "print(\" - Accuracy:\", accuracy_score(y_test, y_pred_baseline))\n",
        "print(\" - ROC-AUC:\", roc_auc_score(y_test, y_prob_baseline))\n",
        "print(\" - PR-AUC :\", average_precision_score(y_test, y_prob_baseline))\n",
        "\n",
        "# ===========================\n",
        "# 4) Model candidates (Bagging vs Boosting)\n",
        "#    - RandomForestClassifier (bagging family)\n",
        "#    - HistGradientBoostingClassifier (boosting family; fast and handles large data)\n",
        "# Overfitting controls included via hyperparams\n",
        "# ===========================\n",
        "rf = RandomForestClassifier(\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced_subsample',  # handle imbalance\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "hgb = HistGradientBoostingClassifier(\n",
        "    random_state=42,\n",
        "    early_stopping=True,\n",
        "    scoring='roc_auc'\n",
        ")\n",
        "\n",
        "# ===========================\n",
        "# 5) Cross-validation strategy (Stratified K-Fold)\n",
        "# ===========================\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# ===========================\n",
        "# 6) Hyperparameter grids (small grid for demonstration)\n",
        "# ===========================\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [6, 12, None],\n",
        "    'min_samples_leaf': [2, 5],\n",
        "    'max_features': ['sqrt']  # typical choice for RF\n",
        "}\n",
        "\n",
        "hgb_param_grid = {\n",
        "    'max_iter': [100, 300],\n",
        "    'max_leaf_nodes': [15, 31],\n",
        "    'learning_rate': [0.05, 0.1],\n",
        "    'min_samples_leaf': [20, 50]  # large to reduce overfitting\n",
        "}\n",
        "\n",
        "# ===========================\n",
        "# 7) GridSearchCV for RF\n",
        "# ===========================\n",
        "print(\"\\nTuning RandomForest (GridSearchCV) ... (this may take a minute)\")\n",
        "rf_grid = GridSearchCV(\n",
        "    rf,\n",
        "    rf_param_grid,\n",
        "    scoring='roc_auc',\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=0\n",
        ")\n",
        "rf_grid.fit(X_train, y_train)\n",
        "best_rf = rf_grid.best_estimator_\n",
        "print(\"Best RF params:\", rf_grid.best_params_)\n",
        "print(\"Best RF CV ROC-AUC: {:.4f}\".format(rf_grid.best_score_))\n",
        "\n",
        "# ===========================\n",
        "# 8) GridSearchCV for HGB\n",
        "# ===========================\n",
        "print(\"\\nTuning HistGradientBoosting (GridSearchCV) ...\")\n",
        "hgb_grid = GridSearchCV(\n",
        "    hgb,\n",
        "    hgb_param_grid,\n",
        "    scoring='roc_auc',\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=0\n",
        ")\n",
        "hgb_grid.fit(X_train, y_train)\n",
        "best_hgb = hgb_grid.best_estimator_\n",
        "print(\"Best HGB params:\", hgb_grid.best_params_)\n",
        "print(\"Best HGB CV ROC-AUC: {:.4f}\".format(hgb_grid.best_score_))\n",
        "\n",
        "# ===========================\n",
        "# 9) Final evaluation on hold-out test set\n",
        "# ===========================\n",
        "def evaluate_model(model, X_test, y_test, name=\"Model\"):\n",
        "    y_prob = model.predict_proba(X_test)[:,1]\n",
        "    y_pred = model.predict(X_test)\n",
        "    roc = roc_auc_score(y_test, y_prob)\n",
        "    pr = average_precision_score(y_test, y_prob)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\n{name} final test results:\")\n",
        "    print(\" - Accuracy : {:.4f}\".format(acc))\n",
        "    print(\" - ROC-AUC  : {:.4f}\".format(roc))\n",
        "    print(\" - PR-AUC   : {:.4f}\".format(pr))\n",
        "    print(\" - Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\" - Classification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
        "    return {\"roc_auc\": roc, \"pr_auc\": pr, \"accuracy\": acc}\n",
        "\n",
        "rf_metrics = evaluate_model(best_rf, X_test, y_test, name=\"RandomForest (Bagging)\")\n",
        "hgb_metrics = evaluate_model(best_hgb, X_test, y_test, name=\"HistGradientBoosting (Boosting)\")\n",
        "\n",
        "# ===========================\n",
        "# 10) Compare via cross-validated ROC-AUC (repeated CV)\n",
        "# ===========================\n",
        "print(\"\\nCross-validated ROC-AUC (5-fold) on training set:\")\n",
        "rf_cv_scores = cross_val_score(best_rf, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
        "hgb_cv_scores = cross_val_score(best_hgb, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
        "print(\" - RF CV ROC-AUC mean ± std:\", np.mean(rf_cv_scores), \"±\", np.std(rf_cv_scores))\n",
        "print(\" - HGB CV ROC-AUC mean ± std:\", np.mean(hgb_cv_scores), \"±\", np.std(hgb_cv_scores))\n",
        "\n",
        "# ===========================\n",
        "# 11) Feature importance for interpretation (permutation importance on test)\n",
        "# ===========================\n",
        "print(\"\\nComputing permutation importances (test set) for best model (RF)...\")\n",
        "perm = permutation_importance(best_rf, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "imp_df = pd.DataFrame({\n",
        "    \"feature\": X_test.columns,\n",
        "    \"importance_mean\": perm.importances_mean,\n",
        "    \"importance_std\": perm.importances_std\n",
        "}).sort_values(by=\"importance_mean\", ascending=False).reset_index(drop=True)\n",
        "print(imp_df.head(8))\n",
        "\n",
        "# ===========================\n",
        "# 12) Notes printed for assignment\n",
        "# ===========================\n",
        "print(\"\\nNotes:\")\n",
        "print(\"- We used class_weight/balancing and PR-AUC alongside ROC-AUC because default is a rare event.\")\n",
        "print(\"- We controlled overfitting via max_depth/min_samples_leaf (RF) and learning_rate/early stopping + min_samples_leaf (HGB).\")\n",
        "print(\"- Use time-based CV in production if data has time ordering (here we used StratifiedKFold for demo).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKWKiUsy0mbz",
        "outputId": "eefc60cb-9496-404c-f850-8fbfe71cd1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (20000, 20)\n",
            "Default rate: 7.46%\n",
            "Train shape: (15000, 20) Test shape: (5000, 20)\n",
            "\n",
            "Baseline Logistic Regression (quick check):\n",
            " - Accuracy: 0.7804\n",
            " - ROC-AUC: 0.8131123357423584\n",
            " - PR-AUC : 0.5082986233210026\n",
            "\n",
            "Tuning RandomForest (GridSearchCV) ... (this may take a minute)\n",
            "Best RF params: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 100}\n",
            "Best RF CV ROC-AUC: 0.9524\n",
            "\n",
            "Tuning HistGradientBoosting (GridSearchCV) ...\n",
            "Best HGB params: {'learning_rate': 0.05, 'max_iter': 100, 'max_leaf_nodes': 31, 'min_samples_leaf': 50}\n",
            "Best HGB CV ROC-AUC: 0.9489\n",
            "\n",
            "RandomForest (Bagging) final test results:\n",
            " - Accuracy : 0.9748\n",
            " - ROC-AUC  : 0.9499\n",
            " - PR-AUC   : 0.8624\n",
            " - Confusion Matrix:\n",
            " [[4618    9]\n",
            " [ 117  256]]\n",
            " - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9753    0.9981    0.9865      4627\n",
            "           1     0.9660    0.6863    0.8025       373\n",
            "\n",
            "    accuracy                         0.9748      5000\n",
            "   macro avg     0.9707    0.8422    0.8945      5000\n",
            "weighted avg     0.9746    0.9748    0.9728      5000\n",
            "\n",
            "\n",
            "HistGradientBoosting (Boosting) final test results:\n",
            " - Accuracy : 0.9748\n",
            " - ROC-AUC  : 0.9455\n",
            " - PR-AUC   : 0.8606\n",
            " - Confusion Matrix:\n",
            " [[4616   11]\n",
            " [ 115  258]]\n",
            " - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9757    0.9976    0.9865      4627\n",
            "           1     0.9591    0.6917    0.8037       373\n",
            "\n",
            "    accuracy                         0.9748      5000\n",
            "   macro avg     0.9674    0.8447    0.8951      5000\n",
            "weighted avg     0.9745    0.9748    0.9729      5000\n",
            "\n",
            "\n",
            "Cross-validated ROC-AUC (5-fold) on training set:\n",
            " - RF CV ROC-AUC mean ± std: 0.9524226164496247 ± 0.005847823903524998\n",
            " - HGB CV ROC-AUC mean ± std: 0.9488612035033517 ± 0.005327861767454309\n",
            "\n",
            "Computing permutation importances (test set) for best model (RF)...\n",
            "                  feature  importance_mean  importance_std\n",
            "0    avg_days_between_txn          0.07056        0.002978\n",
            "1  recent_large_txn_count          0.05082        0.002471\n",
            "2                     age          0.02074        0.001718\n",
            "3           annual_income          0.01340        0.001437\n",
            "4       delinquency_count          0.01260        0.001149\n",
            "5            txn_freq_6mo          0.00724        0.000866\n",
            "6            txn_amt_mean          0.00612        0.000926\n",
            "7    num_credit_inquiries          0.00556        0.001042\n",
            "\n",
            "Notes:\n",
            "- We used class_weight/balancing and PR-AUC alongside ROC-AUC because default is a rare event.\n",
            "- We controlled overfitting via max_depth/min_samples_leaf (RF) and learning_rate/early stopping + min_samples_leaf (HGB).\n",
            "- Use time-based CV in production if data has time ordering (here we used StratifiedKFold for demo).\n"
          ]
        }
      ]
    }
  ]
}